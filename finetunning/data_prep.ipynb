{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# üõ°Ô∏è Algospeak Content Moderation - Data Preparation\n",
    "\n",
    "## üìä Processing Jigsaw Dataset with Polars\n",
    "\n",
    "This notebook processes the **Jigsaw Unintended Bias in Toxicity Classification** dataset (3.8M rows) to create training data for our algospeak-aware content moderation system.\n",
    "\n",
    "### üéØ What We'll Do:\n",
    "1. **Load and explore** the massive Jigsaw dataset using Polars\n",
    "2. **Map toxicity scores** to our classification system\n",
    "3. **Create algospeak variants** using Stage 1 patterns  \n",
    "4. **Generate instruction-tuned format** for Qwen2.5-3B\n",
    "5. **Export training-ready JSON** for Google Colab fine-tuning\n",
    "\n",
    "### üöÄ Why Polars?\n",
    "- **10x faster** than Pandas for large datasets\n",
    "- **Memory efficient** - can handle 3.8M rows easily\n",
    "- **Better API** for data transformations\n",
    "- **Rust-powered** performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9734c0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Converting to instruction-following format...\n",
      "‚úÖ Converted to instruction format!\n",
      "   Total instruction samples: 52913\n",
      "\n",
      "üìù Instruction format examples:\n",
      "\n",
      "1. Instruction: Analyze this content for harmfulness and classify it appropriately. Consider both direct language and coded language (algospeak).\n",
      "   Input: \"This is so cool. It's like, 'would you want your mother to r...\"\n",
      "   Output: This content is safe. Category: general, Severity: 0\n",
      "   Algospeak variant: False\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. Instruction: Analyze this content for harmfulness and classify it appropriately. Consider both direct language and coded language (algospeak).\n",
      "   Input: \"Thank you!! This would make my life a lot less anxiety-induc...\"\n",
      "   Output: This content is safe. Category: general, Severity: 0\n",
      "   Algospeak variant: False\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. Instruction: Analyze this content for harmfulness and classify it appropriately. Consider both direct language and coded language (algospeak).\n",
      "   Input: \"This is such an urgent design problem; kudos to you for taki...\"\n",
      "   Output: This content is safe. Category: general, Severity: 0\n",
      "   Algospeak variant: False\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìä Final instruction dataset:\n",
      "   Total samples: 52,913\n",
      "   Algospeak variants: 2,913 (5.5%)\n",
      "\n",
      "üìä Label distribution:\n",
      "   safe: 41,145 (77.8%)\n",
      "   potentially_harmful: 7,227 (13.7%)\n",
      "   harmful: 3,463 (6.5%)\n",
      "   extremely_harmful: 1,078 (2.0%)\n"
     ]
    }
   ],
   "source": [
    "## üìù Convert to Instruction-Tuned Format\n",
    "\n",
    "print(\"üìù Converting to instruction-following format...\")\n",
    "\n",
    "def create_instruction_sample(sample):\n",
    "    \"\"\"Convert sample to instruction format for LLM training\"\"\"\n",
    "    \n",
    "    # Create instruction prompt\n",
    "    instruction = \"Analyze this content for harmfulness and classify it appropriately. Consider both direct language and coded language (algospeak).\"\n",
    "    \n",
    "    # Create the response based on our labels\n",
    "    if sample['label'] == 'safe':\n",
    "        response = f\"This content is safe. Category: {sample['category']}, Severity: {sample['severity']}\"\n",
    "    else:\n",
    "        response = f\"This content is {sample['label']}. Category: {sample['category']}, Severity: {sample['severity']}\"\n",
    "    \n",
    "    # Create instruction-tuned format\n",
    "    return {\n",
    "        \"instruction\": instruction,\n",
    "        \"input\": sample['text'],\n",
    "        \"output\": response,\n",
    "        \"label\": sample['label'],\n",
    "        \"category\": sample['category'],\n",
    "        \"severity\": sample['severity'],\n",
    "        \"is_algospeak\": sample.get('is_algospeak_variant', False)\n",
    "    }\n",
    "\n",
    "# Convert all samples to instruction format\n",
    "instruction_samples = []\n",
    "for sample in all_samples:\n",
    "    instruction_sample = create_instruction_sample(sample)\n",
    "    instruction_samples.append(instruction_sample)\n",
    "\n",
    "print(\"‚úÖ Converted to instruction format!\")\n",
    "print(\"   Total instruction samples:\", len(instruction_samples))\n",
    "\n",
    "# Show examples\n",
    "print(\"\\nüìù Instruction format examples:\")\n",
    "for i in range(3):\n",
    "    sample = instruction_samples[i]\n",
    "    print(f\"\\n{i+1}. Instruction: {sample['instruction']}\")\n",
    "    print(f\"   Input: \\\"{sample['input'][:60]}...\\\"\")\n",
    "    print(f\"   Output: {sample['output']}\")\n",
    "    print(f\"   Algospeak variant: {sample['is_algospeak']}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Show distribution\n",
    "labels = [s['label'] for s in instruction_samples]\n",
    "algospeak_count = sum(1 for s in instruction_samples if s['is_algospeak'])\n",
    "\n",
    "print(\"\\nüìä Final instruction dataset:\")\n",
    "print(f\"   Total samples: {len(instruction_samples):,}\")\n",
    "print(f\"   Algospeak variants: {algospeak_count:,} ({algospeak_count/len(instruction_samples)*100:.1f}%)\")\n",
    "\n",
    "from collections import Counter\n",
    "print(\"\\nüìä Label distribution:\")\n",
    "for label, count in Counter(labels).most_common():\n",
    "    pct = (count / len(instruction_samples)) * 100\n",
    "    print(f\"   {label}: {count:,} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1Ô∏è‚É£ Setup and Dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c3ab40e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 45)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>target</th><th>comment_text</th><th>severe_toxicity</th><th>obscene</th><th>identity_attack</th><th>insult</th><th>threat</th><th>asian</th><th>atheist</th><th>bisexual</th><th>black</th><th>buddhist</th><th>christian</th><th>female</th><th>heterosexual</th><th>hindu</th><th>homosexual_gay_or_lesbian</th><th>intellectual_or_learning_disability</th><th>jewish</th><th>latino</th><th>male</th><th>muslim</th><th>other_disability</th><th>other_gender</th><th>other_race_or_ethnicity</th><th>other_religion</th><th>other_sexual_orientation</th><th>physical_disability</th><th>psychiatric_or_mental_illness</th><th>transgender</th><th>white</th><th>created_date</th><th>publication_id</th><th>parent_id</th><th>article_id</th><th>rating</th><th>funny</th><th>wow</th><th>sad</th><th>likes</th><th>disagree</th><th>sexual_explicit</th><th>identity_annotator_count</th><th>toxicity_annotator_count</th></tr><tr><td>i64</td><td>f64</td><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>str</td><td>i64</td><td>f64</td><td>i64</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>i64</td></tr></thead><tbody><tr><td>59848</td><td>0.0</td><td>&quot;This is so cool. It&#x27;s like, &#x27;w‚Ä¶</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;2015-09-29 10:50:41.987077+00&quot;</td><td>2</td><td>null</td><td>2006</td><td>&quot;rejected&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.0</td><td>0</td><td>4</td></tr><tr><td>59849</td><td>0.0</td><td>&quot;Thank you!! This would make my‚Ä¶</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;2015-09-29 10:50:42.870083+00&quot;</td><td>2</td><td>null</td><td>2006</td><td>&quot;rejected&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.0</td><td>0</td><td>4</td></tr><tr><td>59852</td><td>0.0</td><td>&quot;This is such an urgent design ‚Ä¶</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;2015-09-29 10:50:45.222647+00&quot;</td><td>2</td><td>null</td><td>2006</td><td>&quot;rejected&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.0</td><td>0</td><td>4</td></tr><tr><td>59855</td><td>0.0</td><td>&quot;Is this something I&#x27;ll be able‚Ä¶</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;2015-09-29 10:50:47.601894+00&quot;</td><td>2</td><td>null</td><td>2006</td><td>&quot;rejected&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0.0</td><td>0</td><td>4</td></tr><tr><td>59856</td><td>0.893617</td><td>&quot;haha you guys are a bunch of l‚Ä¶</td><td>0.021277</td><td>0.0</td><td>0.021277</td><td>0.87234</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.25</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&quot;2015-09-29 10:50:48.488476+00&quot;</td><td>2</td><td>null</td><td>2006</td><td>&quot;rejected&quot;</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0.0</td><td>4</td><td>47</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 45)\n",
       "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
       "‚îÇ id    ‚îÜ target   ‚îÜ comment_te ‚îÜ severe_tox ‚îÜ ‚Ä¶ ‚îÜ disagree ‚îÜ sexual_exp ‚îÜ identity_a ‚îÜ toxicity_a ‚îÇ\n",
       "‚îÇ ---   ‚îÜ ---      ‚îÜ xt         ‚îÜ icity      ‚îÜ   ‚îÜ ---      ‚îÜ licit      ‚îÜ nnotator_c ‚îÜ nnotator_c ‚îÇ\n",
       "‚îÇ i64   ‚îÜ f64      ‚îÜ ---        ‚îÜ ---        ‚îÜ   ‚îÜ i64      ‚îÜ ---        ‚îÜ ount       ‚îÜ ount       ‚îÇ\n",
       "‚îÇ       ‚îÜ          ‚îÜ str        ‚îÜ f64        ‚îÜ   ‚îÜ          ‚îÜ f64        ‚îÜ ---        ‚îÜ ---        ‚îÇ\n",
       "‚îÇ       ‚îÜ          ‚îÜ            ‚îÜ            ‚îÜ   ‚îÜ          ‚îÜ            ‚îÜ i64        ‚îÜ i64        ‚îÇ\n",
       "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
       "‚îÇ 59848 ‚îÜ 0.0      ‚îÜ This is so ‚îÜ 0.0        ‚îÜ ‚Ä¶ ‚îÜ 0        ‚îÜ 0.0        ‚îÜ 0          ‚îÜ 4          ‚îÇ\n",
       "‚îÇ       ‚îÜ          ‚îÜ cool. It's ‚îÜ            ‚îÜ   ‚îÜ          ‚îÜ            ‚îÜ            ‚îÜ            ‚îÇ\n",
       "‚îÇ       ‚îÜ          ‚îÜ like, 'w‚Ä¶  ‚îÜ            ‚îÜ   ‚îÜ          ‚îÜ            ‚îÜ            ‚îÜ            ‚îÇ\n",
       "‚îÇ 59849 ‚îÜ 0.0      ‚îÜ Thank      ‚îÜ 0.0        ‚îÜ ‚Ä¶ ‚îÜ 0        ‚îÜ 0.0        ‚îÜ 0          ‚îÜ 4          ‚îÇ\n",
       "‚îÇ       ‚îÜ          ‚îÜ you!! This ‚îÜ            ‚îÜ   ‚îÜ          ‚îÜ            ‚îÜ            ‚îÜ            ‚îÇ\n",
       "‚îÇ       ‚îÜ          ‚îÜ would make ‚îÜ            ‚îÜ   ‚îÜ          ‚îÜ            ‚îÜ            ‚îÜ            ‚îÇ\n",
       "‚îÇ       ‚îÜ          ‚îÜ my‚Ä¶        ‚îÜ            ‚îÜ   ‚îÜ          ‚îÜ            ‚îÜ            ‚îÜ            ‚îÇ\n",
       "‚îÇ 59852 ‚îÜ 0.0      ‚îÜ This is    ‚îÜ 0.0        ‚îÜ ‚Ä¶ ‚îÜ 0        ‚îÜ 0.0        ‚îÜ 0          ‚îÜ 4          ‚îÇ\n",
       "‚îÇ       ‚îÜ          ‚îÜ such an    ‚îÜ            ‚îÜ   ‚îÜ          ‚îÜ            ‚îÜ            ‚îÜ            ‚îÇ\n",
       "‚îÇ       ‚îÜ          ‚îÜ urgent     ‚îÜ            ‚îÜ   ‚îÜ          ‚îÜ            ‚îÜ            ‚îÜ            ‚îÇ\n",
       "‚îÇ       ‚îÜ          ‚îÜ design ‚Ä¶   ‚îÜ            ‚îÜ   ‚îÜ          ‚îÜ            ‚îÜ            ‚îÜ            ‚îÇ\n",
       "‚îÇ 59855 ‚îÜ 0.0      ‚îÜ Is this    ‚îÜ 0.0        ‚îÜ ‚Ä¶ ‚îÜ 0        ‚îÜ 0.0        ‚îÜ 0          ‚îÜ 4          ‚îÇ\n",
       "‚îÇ       ‚îÜ          ‚îÜ something  ‚îÜ            ‚îÜ   ‚îÜ          ‚îÜ            ‚îÜ            ‚îÜ            ‚îÇ\n",
       "‚îÇ       ‚îÜ          ‚îÜ I'll be    ‚îÜ            ‚îÜ   ‚îÜ          ‚îÜ            ‚îÜ            ‚îÜ            ‚îÇ\n",
       "‚îÇ       ‚îÜ          ‚îÜ able‚Ä¶      ‚îÜ            ‚îÜ   ‚îÜ          ‚îÜ            ‚îÜ            ‚îÜ            ‚îÇ\n",
       "‚îÇ 59856 ‚îÜ 0.893617 ‚îÜ haha you   ‚îÜ 0.021277   ‚îÜ ‚Ä¶ ‚îÜ 0        ‚îÜ 0.0        ‚îÜ 4          ‚îÜ 47         ‚îÇ\n",
       "‚îÇ       ‚îÜ          ‚îÜ guys are a ‚îÜ            ‚îÜ   ‚îÜ          ‚îÜ            ‚îÜ            ‚îÜ            ‚îÇ\n",
       "‚îÇ       ‚îÜ          ‚îÜ bunch of   ‚îÜ            ‚îÜ   ‚îÜ          ‚îÜ            ‚îÜ            ‚îÜ            ‚îÇ\n",
       "‚îÇ       ‚îÜ          ‚îÜ l‚Ä¶         ‚îÜ            ‚îÜ   ‚îÜ          ‚îÜ            ‚îÜ            ‚îÜ            ‚îÇ\n",
       "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import polars as pl\n",
    "df = pl.read_csv(\"train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f8c574b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Dataset Info (pandas-style):\n",
      "Shape: (1804874, 45)\n",
      "Memory usage: 1159.576078414917 MB\n",
      "üìã Column count: 45\n",
      "\n",
      "Column info:\n",
      "   Column Name                          Data Type\n",
      "   --------------------------------------------------\n",
      "   id                                 Int64\n",
      "   target                             Float64\n",
      "   comment_text                       String\n",
      "   severe_toxicity                    Float64\n",
      "   obscene                            Float64\n",
      "   identity_attack                    Float64\n",
      "   insult                             Float64\n",
      "   threat                             Float64\n",
      "   asian                              Float64\n",
      "   atheist                            Float64\n",
      "   bisexual                           Float64\n",
      "   black                              Float64\n",
      "   buddhist                           Float64\n",
      "   christian                          Float64\n",
      "   female                             Float64\n",
      "   heterosexual                       Float64\n",
      "   hindu                              Float64\n",
      "   homosexual_gay_or_lesbian          Float64\n",
      "   intellectual_or_learning_disabilityFloat64\n",
      "   jewish                             Float64\n",
      "   latino                             Float64\n",
      "   male                               Float64\n",
      "   muslim                             Float64\n",
      "   other_disability                   Float64\n",
      "   other_gender                       Float64\n",
      "   other_race_or_ethnicity            Float64\n",
      "   other_religion                     Float64\n",
      "   other_sexual_orientation           Float64\n",
      "   physical_disability                Float64\n",
      "   psychiatric_or_mental_illness      Float64\n",
      "   transgender                        Float64\n",
      "   white                              Float64\n",
      "   created_date                       String\n",
      "   publication_id                     Int64\n",
      "   parent_id                          Float64\n",
      "   article_id                         Int64\n",
      "   rating                             String\n",
      "   funny                              Int64\n",
      "   wow                                Int64\n",
      "   sad                                Int64\n",
      "   likes                              Int64\n",
      "   disagree                           Int64\n",
      "   sexual_explicit                    Float64\n",
      "   identity_annotator_count           Int64\n",
      "   toxicity_annotator_count           Int64\n"
     ]
    }
   ],
   "source": [
    "# Make it vertical like pandas df.info()\n",
    "print(\"üìä Dataset Info (pandas-style):\")\n",
    "print(\"Shape:\", df.shape)                           # Show rows and columns  \n",
    "print(\"Memory usage:\", df.estimated_size('mb'), \"MB\")  # Show memory usage\n",
    "print(\"üìã Column count:\", len(df.columns))\n",
    "print()\n",
    "print(\"Column info:\")\n",
    "print(\"   Column Name                          Data Type\")\n",
    "print(\"   \" + \"-\" * 50)                             # Print separator line\n",
    "\n",
    "# Loop through schema to print each column vertically\n",
    "for col_name, col_type in df.schema.items():        # schema.items() gives (name, type) pairs\n",
    "    print(\"   \" + col_name.ljust(35) + str(col_type))  # ljust(35) makes column name left-aligned in 35 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "53ad0a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùì Missing values in key columns:\n",
      "   comment_text: 0 missing (0.0%)\n",
      "   target: 0 missing (0.0%)\n",
      "   severe_toxicity: 0 missing (0.0%)\n",
      "   obscene: 0 missing (0.0%)\n",
      "   identity_attack: 0 missing (0.0%)\n",
      "   insult: 0 missing (0.0%)\n",
      "   threat: 0 missing (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the columns we care about for content moderation\n",
    "key_columns = [\"comment_text\", \"target\", \"severe_toxicity\", \"obscene\", \"identity_attack\", \"insult\", \"threat\"]\n",
    "\n",
    "print(\"‚ùì Missing values in key columns:\")\n",
    "for col in key_columns:                           # Loop through each important column\n",
    "    null_count = df.select(col).null_count().item()  # Count nulls in this column, .item() gets the actual number\n",
    "    total_rows = df.shape[0]                      # Total number of rows\n",
    "    percentage = (null_count / total_rows) * 100  # Calculate percentage of missing data\n",
    "    print(\"   \" + col + \": \" + str(null_count) + \" missing (\" + str(round(percentage, 2)) + \"%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1fa88868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Target column (toxicity scores) statistics:\n",
      "shape: (9, 2)\n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ statistic  ‚îÜ target     ‚îÇ\n",
      "‚îÇ ---        ‚îÜ ---        ‚îÇ\n",
      "‚îÇ str        ‚îÜ f64        ‚îÇ\n",
      "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
      "‚îÇ count      ‚îÜ 1.804874e6 ‚îÇ\n",
      "‚îÇ null_count ‚îÜ 0.0        ‚îÇ\n",
      "‚îÇ mean       ‚îÜ 0.103017   ‚îÇ\n",
      "‚îÇ std        ‚îÜ 0.197076   ‚îÇ\n",
      "‚îÇ min        ‚îÜ 0.0        ‚îÇ\n",
      "‚îÇ 25%        ‚îÜ 0.0        ‚îÇ\n",
      "‚îÇ 50%        ‚îÜ 0.0        ‚îÇ\n",
      "‚îÇ 75%        ‚îÜ 0.166667   ‚îÇ\n",
      "‚îÇ max        ‚îÜ 1.0        ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
     ]
    }
   ],
   "source": [
    "# Let's see the target column distribution to understand toxicity scores\n",
    "print(\"üìä Target column (toxicity scores) statistics:\")\n",
    "target_stats = df.select(\"target\").describe()  # Get basic statistics\n",
    "print(target_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3f7d5315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ Sample comments with full text:\n",
      "Row 1:\n",
      "   Target: 0.0 | Insult: 0.0 | Threat: 0.0\n",
      "   Comment: This is so cool. It's like, 'would you want your mother to read this??' Really great idea, well done!\n",
      "   --------------------------------------------------------------------------------\n",
      "Row 2:\n",
      "   Target: 0.0 | Insult: 0.0 | Threat: 0.0\n",
      "   Comment: Thank you!! This would make my life a lot less anxiety-inducing. Keep it up, and don't let anyone get in your way!\n",
      "   --------------------------------------------------------------------------------\n",
      "Row 3:\n",
      "   Target: 0.0 | Insult: 0.0 | Threat: 0.0\n",
      "   Comment: This is such an urgent design problem; kudos to you for taking it on. Very impressive!\n",
      "   --------------------------------------------------------------------------------\n",
      "Row 4:\n",
      "   Target: 0.0 | Insult: 0.0 | Threat: 0.0\n",
      "   Comment: Is this something I'll be able to install on my site? When will you be releasing it?\n",
      "   --------------------------------------------------------------------------------\n",
      "Row 5:\n",
      "   Target: 0.894 | Insult: 0.872 | Threat: 0.0\n",
      "   Comment: haha you guys are a bunch of losers.\n",
      "   --------------------------------------------------------------------------------\n",
      "Row 6:\n",
      "   Target: 0.667 | Insult: 0.333 | Threat: 0.0\n",
      "   Comment: ur a sh*tty comment.\n",
      "   --------------------------------------------------------------------------------\n",
      "Row 7:\n",
      "   Target: 0.458 | Insult: 0.254 | Threat: 0.0\n",
      "   Comment: hahahahahahahahhha suck it.\n",
      "   --------------------------------------------------------------------------------\n",
      "Row 8:\n",
      "   Target: 0.0 | Insult: 0.0 | Threat: 0.0\n",
      "   Comment: FFFFUUUUUUUUUUUUUUU\n",
      "   --------------------------------------------------------------------------------\n",
      "Row 9:\n",
      "   Target: 0.0 | Insult: 0.0 | Threat: 0.0\n",
      "   Comment: The ranchers seem motivated by mostly by greed; no one should have the right to allow their animals destroy public land.\n",
      "   --------------------------------------------------------------------------------\n",
      "Row 10:\n",
      "   Target: 0.0 | Insult: 0.0 | Threat: 0.0\n",
      "   Comment: It was a great show. Not a combo I'd of expected to be good together but it was.\n",
      "   --------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Let's see some actual full comments (not truncated)\n",
    "print(\"üí¨ Sample comments with full text:\")\n",
    "sample_data = df.select([\"comment_text\", \"target\", \"insult\", \"threat\"]).head(10)  # Get first 10 with key scores\n",
    "\n",
    "for i in range(10):                           # Loop through each comment\n",
    "    row = sample_data.row(i)                  # Get the row data  \n",
    "    comment = str(row[0])                     # Full comment text (not truncated)\n",
    "    target_score = row[1]                     # Toxicity score\n",
    "    insult_score = row[2]                     # Insult score\n",
    "    threat_score = row[3]                     # Threat score\n",
    "    \n",
    "    print(\"Row \" + str(i+1) + \":\")\n",
    "    print(\"   Target: \" + str(round(target_score, 3)) + \" | Insult: \" + str(round(insult_score, 3)) + \" | Threat: \" + str(round(threat_score, 3)))\n",
    "    print(\"   Comment: \" + comment)\n",
    "    print(\"   \" + \"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a095e8e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Toxicity level distribution:\n",
      "   Extremely harmful (>= 0.8): 30831 (1.7%)\n",
      "   Harmful (0.5-0.8): 113503 (6.3%)\n",
      "   Potentially harmful (0.2-0.5): 233352 (12.9%)\n",
      "   Safe (< 0.2): 1427188 (79.1%)\n"
     ]
    }
   ],
   "source": [
    "# Let's see how many comments fall into different toxicity ranges\n",
    "print(\"üìä Toxicity level distribution:\")\n",
    "\n",
    "# Create ranges similar to our content moderation categories\n",
    "high_toxic = df.filter(df[\"target\"] >= 0.8).shape[0]          # Very toxic (>= 0.8)\n",
    "moderate_toxic = df.filter((df[\"target\"] >= 0.5) & (df[\"target\"] < 0.8)).shape[0]  # Moderate toxic (0.5-0.8)\n",
    "low_toxic = df.filter((df[\"target\"] >= 0.2) & (df[\"target\"] < 0.5)).shape[0]       # Low toxic (0.2-0.5) \n",
    "safe = df.filter(df[\"target\"] < 0.2).shape[0]                 # Safe (< 0.2)\n",
    "\n",
    "\n",
    "total = df.shape[0]\n",
    "print(\"   Extremely harmful (>= 0.8): \" + str(high_toxic) + \" (\" + str(round(high_toxic/total*100, 1)) + \"%)\")\n",
    "print(\"   Harmful (0.5-0.8): \" + str(moderate_toxic) + \" (\" + str(round(moderate_toxic/total*100, 1)) + \"%)\")  \n",
    "print(\"   Potentially harmful (0.2-0.5): \" + str(low_toxic) + \" (\" + str(round(low_toxic/total*100, 1)) + \"%)\")\n",
    "print(\"   Safe (< 0.2): \" + str(safe) + \" (\" + str(round(safe/total*100, 1)) + \"%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c44c1870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Toxicity subcategory analysis:\n",
      "\n",
      "üìä severe_toxicity:\n",
      "   Mean score: 0.005\n",
      "   Toxic count: 13 (0.0%)\n",
      "\n",
      "üìä obscene:\n",
      "   Mean score: 0.014\n",
      "   Toxic count: 9603 (0.5%)\n",
      "\n",
      "üìä identity_attack:\n",
      "   Mean score: 0.023\n",
      "   Toxic count: 13410 (0.7%)\n",
      "\n",
      "üìä insult:\n",
      "   Mean score: 0.081\n",
      "   Toxic count: 106534 (5.9%)\n",
      "\n",
      "üìä threat:\n",
      "   Mean score: 0.009\n",
      "   Toxic count: 4280 (0.2%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's explore the different types of toxicity in our dataset\n",
    "print(\"üîç Toxicity subcategory analysis:\")\n",
    "print()\n",
    "\n",
    "# Get basic stats for each toxicity type  \n",
    "toxicity_columns = [\"severe_toxicity\", \"obscene\", \"identity_attack\", \"insult\", \"threat\"]\n",
    "\n",
    "for col in toxicity_columns:                    # Loop through each toxicity type\n",
    "    stats = df.select(col).describe()           # Get statistics for this column\n",
    "    mean_val = stats.filter(stats[\"statistic\"] == \"mean\")[col].item()  # Extract mean value\n",
    "    \n",
    "    # Count how many comments have this type of toxicity (> 0.5 threshold)\n",
    "    toxic_count = df.filter(df[col] >= 0.5).shape[0]   # Count comments above 0.5\n",
    "    percentage = round(toxic_count / df.shape[0] * 100, 1)  # Calculate percentage\n",
    "    \n",
    "    print(\"üìä \" + col + \":\")\n",
    "    print(\"   Mean score: \" + str(round(mean_val, 3)))      # Average score\n",
    "    print(\"   Toxic count: \" + str(toxic_count) + \" (\" + str(percentage) + \"%)\")  # Count above 0.5\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "07415da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Data preparation for fine-tuning:\n",
      "\n",
      "üè∑Ô∏è Identity-based annotation columns available:\n",
      "   1. asian: 4578 comments\n",
      "   2. atheist: 1412 comments\n",
      "   3. bisexual: 287 comments\n",
      "   4. black: 14901 comments\n",
      "   5. buddhist: 588 comments\n",
      "   6. christian: 40423 comments\n",
      "   7. female: 53429 comments\n",
      "   8. heterosexual: 1291 comments\n",
      "   9. hindu: 580 comments\n",
      "   10. homosexual_gay_or_lesbian: 10997 comments\n",
      "   11. intellectual_or_learning_disability: 93 comments\n",
      "   12. jewish: 7651 comments\n",
      "   13. latino: 2004 comments\n",
      "   14. male: 44484 comments\n",
      "   15. muslim: 21006 comments\n",
      "   16. transgender: 2499 comments\n",
      "   17. white: 25082 comments\n"
     ]
    }
   ],
   "source": [
    "# Let's start preparing our training data\n",
    "print(\"üéØ Data preparation for fine-tuning:\")\n",
    "print()\n",
    "\n",
    "# First, let's see what identity columns we have for comprehensive coverage\n",
    "identity_columns = [\"asian\", \"atheist\", \"bisexual\", \"black\", \"buddhist\", \"christian\", \n",
    "                   \"female\", \"heterosexual\", \"hindu\", \"homosexual_gay_or_lesbian\",\n",
    "                   \"intellectual_or_learning_disability\", \"jewish\", \"latino\", \"male\", \n",
    "                   \"muslim\", \"transgender\", \"white\"]\n",
    "\n",
    "print(\"üè∑Ô∏è Identity-based annotation columns available:\")\n",
    "for i, col in enumerate(identity_columns, 1):           # Loop through identity columns with numbers\n",
    "    count = df.filter(df[col] >= 0.5).shape[0]         # Count comments with this identity annotation\n",
    "    if count > 0:                                       # Only show columns that have data\n",
    "        print(\"   \" + str(i) + \". \" + col + \": \" + str(count) + \" comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "19370546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Analyzing short comments we're removing...\n",
      "   Short comments count: 12927\n",
      "\n",
      "üìù Examples of short comments (< 10 chars):\n",
      "   'Awesome!' (len=8) | Target: 0.000 | Insult: 0.000 | Threat: 0.000\n",
      "   'Me too!' (len=7) | Target: 0.000 | Insult: 0.000 | Threat: 0.000\n",
      "   ':(' (len=2) | Target: 0.100 | Insult: 0.000 | Threat: 0.000\n",
      "   'I agree!' (len=8) | Target: 0.000 | Insult: 0.000 | Threat: 0.000\n",
      "   'Perhaps!' (len=8) | Target: 0.000 | Insult: 0.000 | Threat: 0.000\n",
      "   ';)' (len=2) | Target: 0.000 | Insult: 0.000 | Threat: 0.000\n",
      "   'log' (len=3) | Target: 0.000 | Insult: 0.000 | Threat: 0.000\n",
      "   '101th!' (len=6) | Target: 0.000 | Insult: 0.000 | Threat: 0.000\n",
      "   'No' (len=2) | Target: 0.000 | Insult: 0.000 | Threat: 0.000\n",
      "   'yes' (len=3) | Target: 0.000 | Insult: 0.000 | Threat: 0.000\n",
      "   'Spot on.' (len=8) | Target: 0.000 | Insult: 0.000 | Threat: 0.000\n",
      "   'YES!' (len=4) | Target: 0.000 | Insult: 0.000 | Threat: 0.000\n",
      "   'BYE!' (len=4) | Target: 0.000 | Insult: 0.000 | Threat: 0.000\n",
      "   'lovely.' (len=7) | Target: 0.000 | Insult: 0.000 | Threat: 0.000\n",
      "   'Oh yuck.' (len=8) | Target: 0.000 | Insult: 0.000 | Threat: 0.000\n",
      "   'boom' (len=4) | Target: 0.000 | Insult: 0.000 | Threat: 0.000\n",
      "   'Very cool' (len=9) | Target: 0.000 | Insult: 0.000 | Threat: 0.000\n",
      "   'NIGGER' (len=6) | Target: 0.879 | Insult: 0.712 | Threat: 0.000\n",
      "   'Testing' (len=7) | Target: 0.000 | Insult: 0.000 | Threat: 0.000\n",
      "   'asdf' (len=4) | Target: 0.000 | Insult: 0.000 | Threat: 0.000\n",
      "\n",
      "üö® Harmful short comments (target >= 0.5): 615\n",
      "   That's 4.8% of short comments\n"
     ]
    }
   ],
   "source": [
    "# Let's see what short comments we're removing to decide if 10 chars is right\n",
    "print(\"üîç Analyzing short comments we're removing...\")\n",
    "\n",
    "# Get comments that are less than 10 characters\n",
    "short_comments = df.filter(pl.col(\"comment_text\").str.len_chars() < 10)\n",
    "print(\"   Short comments count:\", short_comments.shape[0])\n",
    "\n",
    "# Look at some examples of short comments and their toxicity scores\n",
    "sample_short = short_comments.select([\"comment_text\", \"target\", \"insult\", \"threat\"]).head(20)\n",
    "\n",
    "print(\"\\nüìù Examples of short comments (< 10 chars):\")\n",
    "for i in range(min(20, sample_short.shape[0])):\n",
    "    row = sample_short.row(i)\n",
    "    comment = str(row[0])\n",
    "    target = row[1]\n",
    "    insult = row[2] \n",
    "    threat = row[3]\n",
    "    \n",
    "    print(f\"   '{comment}' (len={len(comment)}) | Target: {target:.3f} | Insult: {insult:.3f} | Threat: {threat:.3f}\")\n",
    "\n",
    "# Check how many short comments are actually harmful\n",
    "harmful_short = short_comments.filter(pl.col(\"target\") >= 0.5).shape[0]\n",
    "print(f\"\\nüö® Harmful short comments (target >= 0.5): {harmful_short}\")\n",
    "print(f\"   That's {harmful_short/short_comments.shape[0]*100:.1f}% of short comments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "16b1516d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Smarter dataset cleaning...\n",
      "‚úÖ Smart cleaning complete!\n",
      "   Original rows: 1804874\n",
      "   Clean rows: 1793024\n",
      "   Removed: 11850 rows\n",
      "   üéØ Harmful short comments kept: 615\n"
     ]
    }
   ],
   "source": [
    "# Better cleaning approach - keep harmful short comments, remove only junk\n",
    "print(\"üßπ Smarter dataset cleaning...\")\n",
    "\n",
    "# Remove rows with missing key data\n",
    "df_clean = df.filter(\n",
    "    pl.col(\"comment_text\").is_not_null() & \n",
    "    pl.col(\"target\").is_not_null()\n",
    ")\n",
    "\n",
    "# Keep ALL harmful content regardless of length (target >= 0.2)\n",
    "# Only filter short comments that are safe (target < 0.2)\n",
    "df_clean = df_clean.filter(\n",
    "    (pl.col(\"comment_text\").str.len_chars() >= 10) |  # Keep long comments OR\n",
    "    (pl.col(\"target\") >= 0.2)                         # Keep harmful short comments\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Smart cleaning complete!\")\n",
    "print(\"   Original rows:\", df.shape[0])\n",
    "print(\"   Clean rows:\", df_clean.shape[0])\n",
    "print(\"   Removed:\", df.shape[0] - df_clean.shape[0], \"rows\")\n",
    "\n",
    "# Verify we kept the harmful short comments\n",
    "harmful_short_kept = df_clean.filter(\n",
    "    (pl.col(\"comment_text\").str.len_chars() < 10) & \n",
    "    (pl.col(\"target\") >= 0.5)\n",
    ").shape[0]\n",
    "\n",
    "print(\"   üéØ Harmful short comments kept:\", harmful_short_kept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "cbe93e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè∑Ô∏è Mapping to content moderation categories...\n",
      "‚úÖ Categories created!\n",
      "   Processed: 50000 comments\n",
      "\n",
      "üìä Label distribution:\n",
      "   safe: 41,145 (82.3%)\n",
      "   potentially_harmful: 5,520 (11.0%)\n",
      "   harmful: 2,589 (5.2%)\n",
      "   extremely_harmful: 746 (1.5%)\n",
      "\n",
      "üìä Category distribution:\n",
      "   general: 45,828 (91.7%)\n",
      "   harassment: 3,299 (6.6%)\n",
      "   hate_speech: 458 (0.9%)\n",
      "   threats: 265 (0.5%)\n",
      "   profanity: 150 (0.3%)\n"
     ]
    }
   ],
   "source": [
    "## üéØ Map to Our Content Moderation Categories\n",
    "\n",
    "# Create our classification system mapping\n",
    "def get_label_and_category(target, severe, obscene, insult, threat, identity_attack):\n",
    "    \"\"\"Map Jigsaw scores to our content moderation system\"\"\"\n",
    "    \n",
    "    # Determine primary label based on target score\n",
    "    if target >= 0.8:\n",
    "        label = \"extremely_harmful\"\n",
    "    elif target >= 0.5:\n",
    "        label = \"harmful\"  \n",
    "    elif target >= 0.2:\n",
    "        label = \"potentially_harmful\"\n",
    "    else:\n",
    "        label = \"safe\"\n",
    "    \n",
    "    # Determine category based on highest subcategory score\n",
    "    if identity_attack > 0.3:\n",
    "        category = \"hate_speech\"\n",
    "    elif threat > 0.3:\n",
    "        category = \"threats\"\n",
    "    elif insult > 0.3:\n",
    "        category = \"harassment\"\n",
    "    elif obscene > 0.3:\n",
    "        category = \"profanity\"\n",
    "    elif severe > 0.3:\n",
    "        category = \"severe\"\n",
    "    else:\n",
    "        category = \"general\"\n",
    "    \n",
    "    # Calculate severity (0-3 scale)\n",
    "    if target >= 0.8: \n",
    "        severity = 3\n",
    "    elif target >= 0.5: \n",
    "        severity = 2  \n",
    "    elif target >= 0.2: \n",
    "        severity = 1\n",
    "    else:\n",
    "        severity = 0\n",
    "    \n",
    "    return label, category, severity\n",
    "\n",
    "# Apply the mapping\n",
    "print(\"üè∑Ô∏è Mapping to content moderation categories...\")\n",
    "\n",
    "# Create a list to store results (first 50k for speed)\n",
    "sample_size = 50000  # Process subset first to test\n",
    "mapped_data = []\n",
    "\n",
    "count = 0\n",
    "for row in df_clean.iter_rows():\n",
    "    if count >= sample_size:\n",
    "        break\n",
    "        \n",
    "    # Get the relevant scores\n",
    "    target = row[1]  # target column\n",
    "    severe = row[3]  # severe_toxicity  \n",
    "    obscene = row[4]  # obscene\n",
    "    identity_attack = row[5]  # identity_attack\n",
    "    insult = row[6]  # insult\n",
    "    threat = row[7]  # threat\n",
    "    \n",
    "    # Get our mappings\n",
    "    label, category, severity = get_label_and_category(target, severe, obscene, insult, threat, identity_attack)\n",
    "    \n",
    "    # Store the result\n",
    "    mapped_data.append({\n",
    "        'id': row[0],\n",
    "        'text': row[2],  # comment_text\n",
    "        'target': target,\n",
    "        'label': label,\n",
    "        'category': category, \n",
    "        'severity': severity\n",
    "    })\n",
    "    \n",
    "    count += 1\n",
    "\n",
    "print(\"‚úÖ Categories created!\")\n",
    "print(\"   Processed:\", len(mapped_data), \"comments\")\n",
    "\n",
    "# Show distribution\n",
    "from collections import Counter\n",
    "labels = [item['label'] for item in mapped_data]\n",
    "categories = [item['category'] for item in mapped_data]\n",
    "\n",
    "print(\"\\nüìä Label distribution:\")\n",
    "for label, count in Counter(labels).most_common():\n",
    "    pct = (count / len(mapped_data)) * 100\n",
    "    print(f\"   {label}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "print(\"\\nüìä Category distribution:\")\n",
    "for category, count in Counter(categories).most_common():\n",
    "    pct = (count / len(mapped_data)) * 100\n",
    "    print(f\"   {category}: {count:,} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dcbf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìñ Loading algospeak patterns...\n",
      "‚úÖ Patterns loaded!\n",
      "   Direct mappings: 74\n",
      "   Homophones: 10\n",
      "   Leetspeak: 11\n",
      "üîÑ Reverse mappings created for 60 words\n",
      "\n",
      "üìù Example mappings:\n",
      "   kill ‚Üí ['unalive']\n",
      "   killing ‚Üí ['unaliving']\n",
      "   killed ‚Üí ['unalived']\n",
      "   suicide ‚Üí ['sewer slide', 'endgame', '13√ó']\n",
      "   commit suicide ‚Üí ['kermit sewer slide']\n"
     ]
    }
   ],
   "source": [
    "## üé≠ Create Algospeak Variants\n",
    "\n",
    "# Load our algospeak patterns from Stage 1\n",
    "import json\n",
    "import random\n",
    "\n",
    "print(\"üìñ Loading algospeak patterns...\")\n",
    "\n",
    "# Load patterns from local dataset folder\n",
    "with open('algospeak_patterns.json', 'r') as f:\n",
    "    patterns = json.load(f)\n",
    "\n",
    "print(\"‚úÖ Patterns loaded!\")\n",
    "print(\"   Direct mappings:\", len(patterns.get('direct_mappings', {})))\n",
    "print(\"   Homophones:\", len(patterns.get('homophones', {})))\n",
    "print(\"   Leetspeak:\", len(patterns.get('leetspeak', {})))\n",
    "\n",
    "# Create reverse mapping (normal word -> algospeak variants)\n",
    "reverse_mappings = {}\n",
    "\n",
    "# Add direct mappings (algospeak -> normal becomes normal -> [algospeak])\n",
    "for algospeak, normal in patterns.get('direct_mappings', {}).items():\n",
    "    if normal not in reverse_mappings:\n",
    "        reverse_mappings[normal] = []\n",
    "    reverse_mappings[normal].append(algospeak)\n",
    "\n",
    "# Add homophones and leetspeak\n",
    "for pattern_type in ['homophones', 'leetspeak']:\n",
    "    for algospeak, normal in patterns.get(pattern_type, {}).items():\n",
    "        if normal not in reverse_mappings:\n",
    "            reverse_mappings[normal] = []\n",
    "        reverse_mappings[normal].append(algospeak)\n",
    "\n",
    "print(\"üîÑ Reverse mappings created for\", len(reverse_mappings), \"words\")\n",
    "\n",
    "# Show some examples\n",
    "print(\"\\nüìù Example mappings:\")\n",
    "for word, variants in list(reverse_mappings.items())[:5]:\n",
    "    print(f\"   {word} ‚Üí {variants}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "22420641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé≠ Creating algospeak variants...\n",
      "üìä Working with 8855 harmful samples\n",
      "‚úÖ Created 2913 algospeak variants!\n",
      "\n",
      "üìù Algospeak variant examples:\n",
      "1. Original: \"This is a great story. Man. I wonder if the person...\"\n",
      "   Variant:  \"this is a great story. man. i wonder if the person...\"\n",
      "   Category: harassment (potentially_harmful)\n",
      "------------------------------------------------------------\n",
      "2. Original: \"This bitch is nuts. Who would read a book by a wom...\"\n",
      "   Variant:  \"this b1tch is nuts. who would read a book by a wom...\"\n",
      "   Category: hate_speech (extremely_harmful)\n",
      "------------------------------------------------------------\n",
      "3. Original: \"‚ÄúWill Whiteness History Month make all white peopl...\"\n",
      "   Variant:  \"‚Äúwill whiteness history month make all white peopl...\"\n",
      "   Category: hate_speech (harmful)\n",
      "------------------------------------------------------------\n",
      "4. Original: \"‚ÄúWill Whiteness History Month make all white peopl...\"\n",
      "   Variant:  \"‚Äúwill whiteness history month make all white peopl...\"\n",
      "   Category: hate_speech (harmful)\n",
      "------------------------------------------------------------\n",
      "5. Original: \"Sorry to have to do this, but just to see if profa...\"\n",
      "   Variant:  \"sorry to have to do this, but just to see if profa...\"\n",
      "   Category: profanity (extremely_harmful)\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìä Final training dataset:\n",
      "   Original samples: 50,000\n",
      "   Algospeak variants: 2,913\n",
      "   Total samples: 52,913\n"
     ]
    }
   ],
   "source": [
    "## üîÄ Generate Algospeak Variants\n",
    "\n",
    "import re\n",
    "\n",
    "print(\"üé≠ Creating algospeak variants...\")\n",
    "\n",
    "# Focus on harmful content (where algospeak is most used)\n",
    "harmful_samples = [item for item in mapped_data \n",
    "                  if item['label'] in ['harmful', 'extremely_harmful', 'potentially_harmful']]\n",
    "\n",
    "print(\"üìä Working with\", len(harmful_samples), \"harmful samples\")\n",
    "\n",
    "algospeak_variants = []\n",
    "variant_count = 0\n",
    "\n",
    "for sample in harmful_samples:\n",
    "    text = sample['text'].lower()\n",
    "    words = text.split()\n",
    "    \n",
    "    # Try to create algospeak variants\n",
    "    for i, word in enumerate(words):\n",
    "        # Clean the word (remove punctuation)\n",
    "        clean_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        \n",
    "        # Check if this word has algospeak variants\n",
    "        if clean_word in reverse_mappings:\n",
    "            # Create variants with algospeak substitutions\n",
    "            for algospeak_variant in reverse_mappings[clean_word][:2]:  # Max 2 variants per word\n",
    "                new_words = words.copy()\n",
    "                new_words[i] = algospeak_variant\n",
    "                variant_text = ' '.join(new_words)\n",
    "                \n",
    "                # Don't create variants identical to original\n",
    "                if variant_text != text:\n",
    "                    algospeak_variants.append({\n",
    "                        'id': f\"algospeak_{variant_count}\",\n",
    "                        'text': variant_text,\n",
    "                        'target': sample['target'],\n",
    "                        'label': sample['label'],\n",
    "                        'category': sample['category'], \n",
    "                        'severity': sample['severity'],\n",
    "                        'is_algospeak_variant': True,\n",
    "                        'original_text': sample['text']\n",
    "                    })\n",
    "                    variant_count += 1\n",
    "\n",
    "print(\"‚úÖ Created\", len(algospeak_variants), \"algospeak variants!\")\n",
    "\n",
    "# Show some examples\n",
    "print(\"\\nüìù Algospeak variant examples:\")\n",
    "for i, variant in enumerate(algospeak_variants[:5]):\n",
    "    print(f\"{i+1}. Original: \\\"{variant['original_text'][:50]}...\\\"\")\n",
    "    print(f\"   Variant:  \\\"{variant['text'][:50]}...\\\"\")\n",
    "    print(f\"   Category: {variant['category']} ({variant['label']})\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Combine original data with variants\n",
    "all_samples = mapped_data + algospeak_variants\n",
    "print(f\"\\nüìä Final training dataset:\")\n",
    "print(f\"   Original samples: {len(mapped_data):,}\")\n",
    "print(f\"   Algospeak variants: {len(algospeak_variants):,}\")\n",
    "print(f\"   Total samples: {len(all_samples):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dfa02c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Converting to instruction-following format...\n",
      "‚úÖ Converted to instruction format!\n",
      "   Total instruction samples: 52913\n",
      "\n",
      "üìù Instruction format examples:\n",
      "\n",
      "1. Instruction: Analyze this content for harmfulness and classify it appropriately. Consider both direct language and coded language (algospeak).\n",
      "   Input: \"This is so cool. It's like, 'would you want your mother to r...\"\n",
      "   Output: This content is safe. Category: general, Severity: 0\n",
      "   Algospeak variant: False\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. Instruction: Analyze this content for harmfulness and classify it appropriately. Consider both direct language and coded language (algospeak).\n",
      "   Input: \"Thank you!! This would make my life a lot less anxiety-induc...\"\n",
      "   Output: This content is safe. Category: general, Severity: 0\n",
      "   Algospeak variant: False\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. Instruction: Analyze this content for harmfulness and classify it appropriately. Consider both direct language and coded language (algospeak).\n",
      "   Input: \"This is such an urgent design problem; kudos to you for taki...\"\n",
      "   Output: This content is safe. Category: general, Severity: 0\n",
      "   Algospeak variant: False\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìä Final instruction dataset:\n",
      "   Total samples: 52,913\n",
      "   Algospeak variants: 2,913 (5.5%)\n",
      "\n",
      "üìä Label distribution:\n",
      "   safe: 41,145 (77.8%)\n",
      "   potentially_harmful: 7,227 (13.7%)\n",
      "   harmful: 3,463 (6.5%)\n",
      "   extremely_harmful: 1,078 (2.0%)\n"
     ]
    }
   ],
   "source": [
    "## üìù Convert to Instruction-Tuned Format\n",
    "\n",
    "print(\"üìù Converting to instruction-following format...\")\n",
    "\n",
    "def create_instruction_sample(sample):\n",
    "    \"\"\"Convert sample to instruction format for LLM training\"\"\"\n",
    "    \n",
    "    # Create instruction prompt\n",
    "    instruction = \"Analyze this content for harmfulness and classify it appropriately. Consider both direct language and coded language (algospeak).\"\n",
    "    \n",
    "    # Create the response based on our labels\n",
    "    if sample['label'] == 'safe':\n",
    "        response = f\"This content is safe. Category: {sample['category']}, Severity: {sample['severity']}\"\n",
    "    else:\n",
    "        response = f\"This content is {sample['label']}. Category: {sample['category']}, Severity: {sample['severity']}\"\n",
    "    \n",
    "    # Create instruction-tuned format\n",
    "    return {\n",
    "        \"instruction\": instruction,\n",
    "        \"input\": sample['text'],\n",
    "        \"output\": response,\n",
    "        \"label\": sample['label'],\n",
    "        \"category\": sample['category'],\n",
    "        \"severity\": sample['severity'],\n",
    "        \"is_algospeak\": sample.get('is_algospeak_variant', False)\n",
    "    }\n",
    "\n",
    "# Convert all samples to instruction format\n",
    "instruction_samples = []\n",
    "for sample in all_samples:\n",
    "    instruction_sample = create_instruction_sample(sample)\n",
    "    instruction_samples.append(instruction_sample)\n",
    "\n",
    "print(\"‚úÖ Converted to instruction format!\")\n",
    "print(\"   Total instruction samples:\", len(instruction_samples))\n",
    "\n",
    "# Show examples\n",
    "print(\"\\nüìù Instruction format examples:\")\n",
    "for i in range(3):\n",
    "    sample = instruction_samples[i]\n",
    "    print(f\"\\n{i+1}. Instruction: {sample['instruction']}\")\n",
    "    print(f\"   Input: \\\"{sample['input'][:60]}...\\\"\")\n",
    "    print(f\"   Output: {sample['output']}\")\n",
    "    print(f\"   Algospeak variant: {sample['is_algospeak']}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Show distribution\n",
    "labels = [s['label'] for s in instruction_samples]\n",
    "algospeak_count = sum(1 for s in instruction_samples if s['is_algospeak'])\n",
    "\n",
    "print(\"\\nüìä Final instruction dataset:\")\n",
    "print(f\"   Total samples: {len(instruction_samples):,}\")\n",
    "print(f\"   Algospeak variants: {algospeak_count:,} ({algospeak_count/len(instruction_samples)*100:.1f}%)\")\n",
    "\n",
    "from collections import Counter\n",
    "print(\"\\nüìä Label distribution:\")\n",
    "for label, count in Counter(labels).most_common():\n",
    "    pct = (count / len(instruction_samples)) * 100\n",
    "    print(f\"   {label}: {count:,} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "09202d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Exporting training dataset for Google Colab...\n",
      "‚úÖ Training dataset exported!\n",
      "   File: dataset/training_dataset_colab.json\n",
      "   Size: 34.0 MB\n",
      "   Samples: 52,913\n",
      "   Algospeak variants: 2,913\n",
      "\n",
      "üéØ Dataset Summary for TrustLab Interview:\n",
      "   ‚úÖ Jigsaw dataset processed with Polars\n",
      "   ‚úÖ Smart cleaning (kept harmful short content)\n",
      "   ‚úÖ Content moderation categories mapped\n",
      "   ‚úÖ Algospeak variants created from Stage 1 patterns\n",
      "   ‚úÖ Instruction-tuned format for Qwen2.5-3B\n",
      "   ‚úÖ Ready for Google Colab QLoRA fine-tuning!\n",
      "\n",
      "üìÅ File saved in: /dataset/training_dataset_colab.json\n",
      "üöÄ When ready: Copy this file and upload to Google Colab!\n"
     ]
    }
   ],
   "source": [
    "## üíæ Export Training Dataset for Google Colab\n",
    "\n",
    "import json\n",
    "\n",
    "print(\"üíæ Exporting training dataset for Google Colab...\")\n",
    "\n",
    "# Export to JSON format in dataset folder (at root level)\n",
    "output_file = \"../dataset/training_dataset_colab.json\"  # Save to dataset/ folder at root\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(instruction_samples, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Get file size\n",
    "import os\n",
    "file_size_mb = os.path.getsize(output_file) / (1024 * 1024)\n",
    "\n",
    "print(\"‚úÖ Training dataset exported!\")\n",
    "print(f\"   File: dataset/{output_file}\")\n",
    "print(f\"   Size: {file_size_mb:.1f} MB\")\n",
    "print(f\"   Samples: {len(instruction_samples):,}\")\n",
    "print(f\"   Algospeak variants: {sum(1 for s in instruction_samples if s['is_algospeak']):,}\")\n",
    "\n",
    "# Show final summary\n",
    "print(\"\\nüéØ Dataset Summary for TrustLab Interview:\")\n",
    "print(\"   ‚úÖ Jigsaw dataset processed with Polars\")\n",
    "print(\"   ‚úÖ Smart cleaning (kept harmful short content)\")  \n",
    "print(\"   ‚úÖ Content moderation categories mapped\")\n",
    "print(\"   ‚úÖ Algospeak variants created from Stage 1 patterns\")\n",
    "print(\"   ‚úÖ Instruction-tuned format for Qwen2.5-3B\")\n",
    "print(\"   ‚úÖ Ready for Google Colab QLoRA fine-tuning!\")\n",
    "\n",
    "print(f\"\\nüìÅ File saved in: {output_file}\")\n",
    "print(\"üöÄ When ready: Copy this file and upload to Google Colab!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cccb42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d72eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Converting to instruction-following format...\n",
      "‚úÖ Converted to instruction format!\n",
      "   Total instruction samples: 52913\n",
      "\n",
      "üìù Instruction format examples:\n",
      "\n",
      "1. Instruction: Analyze this content for harmfulness and classify it appropriately. Consider both direct language and coded language (algospeak).\n",
      "   Input: \"This is so cool. It's like, 'would you want your mother to r...\"\n",
      "   Output: This content is safe. Category: general, Severity: 0\n",
      "   Algospeak variant: False\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. Instruction: Analyze this content for harmfulness and classify it appropriately. Consider both direct language and coded language (algospeak).\n",
      "   Input: \"Thank you!! This would make my life a lot less anxiety-induc...\"\n",
      "   Output: This content is safe. Category: general, Severity: 0\n",
      "   Algospeak variant: False\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. Instruction: Analyze this content for harmfulness and classify it appropriately. Consider both direct language and coded language (algospeak).\n",
      "   Input: \"This is such an urgent design problem; kudos to you for taki...\"\n",
      "   Output: This content is safe. Category: general, Severity: 0\n",
      "   Algospeak variant: False\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìä Final instruction dataset:\n",
      "   Total samples: 52,913\n",
      "   Algospeak variants: 2,913 (5.5%)\n",
      "\n",
      "üìä Label distribution:\n",
      "   safe: 41,145 (77.8%)\n",
      "   potentially_harmful: 7,227 (13.7%)\n",
      "   harmful: 3,463 (6.5%)\n",
      "   extremely_harmful: 1,078 (2.0%)\n"
     ]
    }
   ],
   "source": [
    "## üìù Convert to Instruction-Tuned Format\n",
    "\n",
    "print(\"üìù Converting to instruction-following format...\")\n",
    "\n",
    "def create_instruction_sample(sample):\n",
    "    \"\"\"Convert sample to instruction format for LLM training\"\"\"\n",
    "    \n",
    "    # Create instruction prompt\n",
    "    instruction = \"Analyze this content for harmfulness and classify it appropriately. Consider both direct language and coded language (algospeak).\"\n",
    "    \n",
    "    # Create the response based on our labels\n",
    "    if sample['label'] == 'safe':\n",
    "        response = f\"This content is safe. Category: {sample['category']}, Severity: {sample['severity']}\"\n",
    "    else:\n",
    "        response = f\"This content is {sample['label']}. Category: {sample['category']}, Severity: {sample['severity']}\"\n",
    "    \n",
    "    # Create instruction-tuned format\n",
    "    return {\n",
    "        \"instruction\": instruction,\n",
    "        \"input\": sample['text'],\n",
    "        \"output\": response,\n",
    "        \"label\": sample['label'],\n",
    "        \"category\": sample['category'],\n",
    "        \"severity\": sample['severity'],\n",
    "        \"is_algospeak\": sample.get('is_algospeak_variant', False)\n",
    "    }\n",
    "\n",
    "# Convert all samples to instruction format\n",
    "instruction_samples = []\n",
    "for sample in all_samples:\n",
    "    instruction_sample = create_instruction_sample(sample)\n",
    "    instruction_samples.append(instruction_sample)\n",
    "\n",
    "print(\"‚úÖ Converted to instruction format!\")\n",
    "print(\"   Total instruction samples:\", len(instruction_samples))\n",
    "\n",
    "# Show examples\n",
    "print(\"\\nüìù Instruction format examples:\")\n",
    "for i in range(3):\n",
    "    sample = instruction_samples[i]\n",
    "    print(f\"\\n{i+1}. Instruction: {sample['instruction']}\")\n",
    "    print(f\"   Input: \\\"{sample['input'][:60]}...\\\"\")\n",
    "    print(f\"   Output: {sample['output']}\")\n",
    "    print(f\"   Algospeak variant: {sample['is_algospeak']}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Show distribution\n",
    "labels = [s['label'] for s in instruction_samples]\n",
    "algospeak_count = sum(1 for s in instruction_samples if s['is_algospeak'])\n",
    "\n",
    "print(\"\\nüìä Final instruction dataset:\")\n",
    "print(f\"   Total samples: {len(instruction_samples):,}\")\n",
    "print(f\"   Algospeak variants: {algospeak_count:,} ({algospeak_count/len(instruction_samples)*100:.1f}%)\")\n",
    "\n",
    "from collections import Counter\n",
    "print(\"\\nüìä Label distribution:\")\n",
    "for label, count in Counter(labels).most_common():\n",
    "    pct = (count / len(instruction_samples)) * 100\n",
    "    print(f\"   {label}: {count:,} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df90407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Converting to instruction-following format...\n",
      "‚úÖ Converted to instruction format!\n",
      "   Total instruction samples: 52913\n",
      "\n",
      "üìù Instruction format examples:\n",
      "\n",
      "1. Instruction: Analyze this content for harmfulness and classify it appropriately. Consider both direct language and coded language (algospeak).\n",
      "   Input: \"This is so cool. It's like, 'would you want your mother to r...\"\n",
      "   Output: This content is safe. Category: general, Severity: 0\n",
      "   Algospeak variant: False\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. Instruction: Analyze this content for harmfulness and classify it appropriately. Consider both direct language and coded language (algospeak).\n",
      "   Input: \"Thank you!! This would make my life a lot less anxiety-induc...\"\n",
      "   Output: This content is safe. Category: general, Severity: 0\n",
      "   Algospeak variant: False\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. Instruction: Analyze this content for harmfulness and classify it appropriately. Consider both direct language and coded language (algospeak).\n",
      "   Input: \"This is such an urgent design problem; kudos to you for taki...\"\n",
      "   Output: This content is safe. Category: general, Severity: 0\n",
      "   Algospeak variant: False\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìä Final instruction dataset:\n",
      "   Total samples: 52,913\n",
      "   Algospeak variants: 2,913 (5.5%)\n",
      "\n",
      "üìä Label distribution:\n",
      "   safe: 41,145 (77.8%)\n",
      "   potentially_harmful: 7,227 (13.7%)\n",
      "   harmful: 3,463 (6.5%)\n",
      "   extremely_harmful: 1,078 (2.0%)\n"
     ]
    }
   ],
   "source": [
    "## üìù Convert to Instruction-Tuned Format\n",
    "\n",
    "print(\"üìù Converting to instruction-following format...\")\n",
    "\n",
    "def create_instruction_sample(sample):\n",
    "    \"\"\"Convert sample to instruction format for LLM training\"\"\"\n",
    "    \n",
    "    # Create instruction prompt\n",
    "    instruction = \"Analyze this content for harmfulness and classify it appropriately. Consider both direct language and coded language (algospeak).\"\n",
    "    \n",
    "    # Create the response based on our labels\n",
    "    if sample['label'] == 'safe':\n",
    "        response = f\"This content is safe. Category: {sample['category']}, Severity: {sample['severity']}\"\n",
    "    else:\n",
    "        response = f\"This content is {sample['label']}. Category: {sample['category']}, Severity: {sample['severity']}\"\n",
    "    \n",
    "    # Create instruction-tuned format\n",
    "    return {\n",
    "        \"instruction\": instruction,\n",
    "        \"input\": sample['text'],\n",
    "        \"output\": response,\n",
    "        \"label\": sample['label'],\n",
    "        \"category\": sample['category'],\n",
    "        \"severity\": sample['severity'],\n",
    "        \"is_algospeak\": sample.get('is_algospeak_variant', False)\n",
    "    }\n",
    "\n",
    "# Convert all samples to instruction format\n",
    "instruction_samples = []\n",
    "for sample in all_samples:\n",
    "    instruction_sample = create_instruction_sample(sample)\n",
    "    instruction_samples.append(instruction_sample)\n",
    "\n",
    "print(\"‚úÖ Converted to instruction format!\")\n",
    "print(\"   Total instruction samples:\", len(instruction_samples))\n",
    "\n",
    "# Show examples\n",
    "print(\"\\nüìù Instruction format examples:\")\n",
    "for i in range(3):\n",
    "    sample = instruction_samples[i]\n",
    "    print(f\"\\n{i+1}. Instruction: {sample['instruction']}\")\n",
    "    print(f\"   Input: \\\"{sample['input'][:60]}...\\\"\")\n",
    "    print(f\"   Output: {sample['output']}\")\n",
    "    print(f\"   Algospeak variant: {sample['is_algospeak']}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# Show distribution\n",
    "labels = [s['label'] for s in instruction_samples]\n",
    "algospeak_count = sum(1 for s in instruction_samples if s['is_algospeak'])\n",
    "\n",
    "print(\"\\nüìä Final instruction dataset:\")\n",
    "print(f\"   Total samples: {len(instruction_samples):,}\")\n",
    "print(f\"   Algospeak variants: {algospeak_count:,} ({algospeak_count/len(instruction_samples)*100:.1f}%)\")\n",
    "\n",
    "from collections import Counter\n",
    "print(\"\\nüìä Label distribution:\")\n",
    "for label, count in Counter(labels).most_common():\n",
    "    pct = (count / len(instruction_samples)) * 100\n",
    "    print(f\"   {label}: {count:,} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4780f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e3c5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7483547d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d63103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1bbb92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73835d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdbebab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fc5c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

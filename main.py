#!/usr/bin/env python3
"""
üõ°Ô∏è ALGOSPEAK CONTENT MODERATION API

Complete API using our simple normalizer + classifier:
- normalizer.py: algospeak ‚Üí normal text
- classifier.py: text ‚Üí harmful/safe classification

Usage: POST /moderate with {"text": "I want to unalive myself"}
"""

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import Dict, Any, Optional
import uvicorn

# Import our components (now in root directory)
from normalizer import SimpleNormalizer
try:
    from classifier import SimpleClassifier
    classifier_available = True
except ImportError as e:
    print(f"‚ö†Ô∏è Classifier not available: {e}")
    classifier_available = False

app = FastAPI(
    title="üõ°Ô∏è Algospeak Content Moderation API",
    description="""
    ## Simple Two-Stage Content Moderation
    
    **Stage 1**: Normalize algospeak (unalive ‚Üí kill)
    **Stage 2**: AI classification (kill myself ‚Üí extremely_harmful)
    
    **Clean & Simple Architecture!**
    """,
    version="1.0.0"
)

class ModerationRequest(BaseModel):
    text: str

class ModerationResponse(BaseModel):
    original_text: str
    normalized_text: str
    algospeak_detected: bool
    classification: str
    stage1_status: str
    stage2_status: str

# Initialize components
print("üîß Initializing Algospeak Moderation API...")
normalizer = SimpleNormalizer()
if classifier_available:
    classifier = SimpleClassifier()
    print("‚úÖ Both normalizer and classifier loaded!")
else:
    print("‚ö†Ô∏è Only normalizer loaded, classifier needs Ollama")

@app.get("/")
async def root():
    """API health check."""
    return {
        "message": "üõ°Ô∏è Algospeak Content Moderation API",
        "status": "active",
        "architecture": {
            "normalizer": "normalizer.py (103 lines)",
            "classifier": "classifier.py (145 lines)", 
            "api": "main.py (this file)"
        },
        "workflow": {
            "1": "POST /moderate with text",
            "2": "Normalize algospeak patterns", 
            "3": "AI classification via Ollama",
            "4": "Return complete results"
        },
        "example": {
            "input": "I want to unalive myself",
            "normalized": "I want to kill myself",
            "classification": "extremely_harmful, self_harm"
        }
    }

@app.post("/moderate", response_model=ModerationResponse)
async def moderate_content(request: ModerationRequest):
    """
    Complete moderation pipeline: Algospeak detection + AI classification.
    """
    try:
        # Stage 1: Normalize algospeak
        print(f"üìù Input: {request.text}")
        normalized_text = normalizer.normalize(request.text)
        algospeak_detected = normalized_text != request.text
        
        if algospeak_detected:
            stage1_status = "algospeak_normalized"
            print(f"üîÑ Normalized algospeak detected")
        else:
            stage1_status = "no_algospeak_found"
            print(f"‚û°Ô∏è No algospeak patterns found")
        
        # Stage 2: AI Classification (if available)
        if classifier_available:
            print(f"ü§ñ Running AI classification...")
            classification_result = classifier.classify(request.text)
            
            if 'error' in classification_result:
                stage2_status = "ollama_unavailable"
                classification = f"‚ö†Ô∏è {classification_result['error']}"
                print(f"‚ùå Classification failed: {classification_result['error']}")
            else:
                stage2_status = "ai_classified"
                classification = str(classification_result.get('classification', 'Unknown'))
                print(f"‚úÖ AI classification completed")
        else:
            stage2_status = "classifier_not_loaded"
            classification = "Classifier module not available"
            print(f"‚ö†Ô∏è Classifier not available")
        
        result = ModerationResponse(
            original_text=request.text,
            normalized_text=normalized_text,
            algospeak_detected=algospeak_detected,
            classification=classification,
            stage1_status=stage1_status,
            stage2_status=stage2_status
        )
        
        print(f"ÔøΩÔøΩ Complete: {stage1_status} + {stage2_status}")
        return result
        
    except Exception as e:
        print(f"‚ùå Error in moderation pipeline: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Moderation failed: {str(e)}")

@app.get("/demo")
async def demo():
    """Demo endpoint showing normalizer working."""
    test_cases = [
        "I want to unalive myself",
        "This is seggs content", 
        "I killed it at work today",
        "Great job on that presentation!"
    ]
    
    results = []
    for text in test_cases:
        try:
            normalized = normalizer.normalize(text)
            results.append({
                "input": text,
                "normalized": normalized,
                "algospeak_detected": normalized != text,
                "status": "‚úÖ Working"
            })
        except Exception as e:
            results.append({
                "input": text,
                "error": str(e),
                "status": "‚ùå Error"
            })
    
    return {
        "demo": "Algospeak Moderation Pipeline Demo",
        "test_results": results,
        "note": "AI classification requires trained model via Ollama",
        "files": {
            "normalizer": "normalizer.py",
            "classifier": "classifier.py", 
            "patterns": "finetunning/dataset/algospeak_patterns.json"
        }
    }

@app.get("/health")
async def health_check():
    """Detailed health check."""
    normalizer_working = False
    classifier_working = False
    
    try:
        # Test normalizer
        test_result = normalizer.normalize("unalive")
        normalizer_working = test_result == "kill"
    except Exception as e:
        pass
    
    try:
        # Test classifier (if available)
        if classifier_available:
            # Just check if it initializes
            classifier_working = True
    except Exception as e:
        pass
        
    return {
        "api": "healthy",
        "normalizer": "‚úÖ working" if normalizer_working else "‚ùå error",
        "classifier": "‚úÖ loaded" if classifier_working else "‚ö†Ô∏è unavailable", 
        "patterns_loaded": len(getattr(normalizer, 'patterns', {})),
        "project_structure": {
            "normalizer.py": "103 lines",
            "classifier.py": "145 lines",
            "main.py": "~180 lines",
            "total": "~428 lines (vs 2700+ before!)"
        }
    }

if __name__ == "__main__":
    print("üöÄ Starting Algospeak Content Moderation API...")
    print("üìã Available endpoints:")
    print("   GET  /       - API info & examples")
    print("   POST /moderate - Moderate content")
    print("   GET  /demo   - Test normalizer")
    print("   GET  /health - System health check")
    print("   GET  /docs  - API documentation")
    print()
    uvicorn.run(app, host="0.0.0.0", port=8000)



